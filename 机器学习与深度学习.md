JDK

<img src="D:\File\typora_file\image-20240918155253339.png" alt="image-20240918155253339" style="zoom:80%;" />

this 就是一个变量，可以用在方法中，来拿到当前对象



# 机器学习

Problem formulation、Collect&process data、Train&tune models、Deploy models、Monitor

## Data Acquisition 数据获取

一些常见的数据集

<img src="D:\File\typora_file\image-20241005115320585.png" alt="image-20241005115320585" style="zoom:80%;" />

**Where to find datasets**  当下常用的数据集

<img src="D:\File\typora_file\image-20241005115613356.png" alt="image-20241005115613356" style="zoom:80%;" />

Data integration 

### 网页数据抓取 Web Scraping

模拟输入

beautifulsoup

**爬虫：**

<img src="D:\File\typora_file\image-20241005160104448.png" alt="image-20241005160104448" style="zoom:80%;" />



<img src="D:\File\typora_file\image-20241005160951298.png" alt="image-20241005160951298" style="zoom:80%;" />



<img src="D:\File\typora_file\image-20241005161451528.png" alt="image-20241005161451528" style="zoom:80%;" />

<img src="D:\File\typora_file\image-20241005162058790.png" alt="image-20241005162058790" style="zoom:80%;" />



网页解析器：https://beautifulsoup.cn/

<img src="D:\File\typora_file\image-20241005164323406.png" alt="image-20241005164323406" style="zoom:80%;" />

## 数据标注

**Semi-Supervised Learning(SSL) 半监督学习**  自训练

主动学习和自训练 结合：

<img src="D:\File\typora_file\image-20241005153019516.png" alt="image-20241005153019516" style="zoom:80%;" />

众包 数据标注 

数据搜集 数据清理 数据变换 特征工程

<img src="D:\File\typora_file\image-20241006153423515.png" alt="image-20241006153423515" style="zoom:80%;" />

## 数据清理

将数据集清理成我们想要的格式
Type of Data Errors:
- Outliers 
- Rule violations
- Pattern violations
Outliners: such as:
 1. 缺失值
 2. 错误值
 3. 错误格式
 4. 错误单位
...
基于规则的检测
基于 payttern 的检测(语义，语法)

## 数据变换 Data Transformation

四种常见：
- Min-max normalization 如 0-1 转换到合理的区间内容
- Z-score normalization 减去均值除以标准差  均值变为 0 标准差变为 1
- Decimal scaling x/10^n 10^n 为位数 max(x)< 1
- Logarithmic transformation log(x)变换

其他常见的数据变换：
- Image Transformation 图片缩放
- Video Transformation 视频帧数变换 切分
- Text Transformation 词根化、语法化 

## 特征工程

固定长度的输入和输出，便于模型训练
- Categorical data: one_hot 编码 0-1 填充  会导致较长的序列
 如：cat [0,0,0,1,0,....]
     dog [0,1,0,0,0,....]
- Date-time:
    such as: [year, month, day, hour, minute, second]
- Features combination:
    such as: [cat, dog]*[male, female] => [cat_male, cat_female, dog_male, dog_female]
- Text Features:
    Represent text as token features
    Pre-trained language models: GloVe, Word2Vec, Gpt3, Bert 将 text 处理输出成一个向量
- IMage/Videos Features:
    Use pretrained models: Inception, ResNet, VGG, MobileNet, EfficientNet
    使用预训练模型提取图像特征 

## 机器学习分类

- Supervised Learning 监督学习 有标号的数据集上训练
- Semi-supervised Learning 自/半监督学习 少量的标号的数据集上训练
- Unsupervised Learning 无监督学习 无标号的数据集上训练 GAN
- Reinforcement Learning 强化学习 模型和环境交互根据反馈去训练 机器人？ 人类

### 监督学习

Loss 函数 (predict, target)^2

Objective 目标函数，优化使 Objective 最小化 最小化损失函数？

Optimization 优化器，优化目标函数

一些常见的监督学习模型：
- Decision Tree 决策树
- Linear methods 线性模型
- Kernel machines 核函数模型 
- Neural Networks 神经网络

#### Decision Tree 决策树

- CLassification Tree 分类
- Regression Tree 回归 映射函数
优点：容易解释
缺点：容易欠拟合 容易过拟合 对数据比较敏感
解决办法
- Random Tree 随机森林

随机森林（Random Tree）：一种集成学习方法，通过构建多个决策树并综合它们的结果来进行预测。
- Gradient boosting trees: Resnet 残差网络

梯度提升树（Gradient boosting trees）：通过逐步添加弱学习器并优化损失函数来增强模型性能；**残差网络（Resnet）** 是用于深度学习的一种架构，通过引入残差块解决梯度消失问题，提高深层网络训练效果。

#### Liner methods 线性模型

- 线性模型做回归
x = [x1, x2, x3, x4,...]
y = wx+b = w1x1+w2x2+w3x3+...+b
Objective: minimize(loss) MSE-mean squared error 平均均方误差
MSE = 1/n(y-y')^2
- 线性模型做分类/softmax 分类 
处理多分类问题
置信度 oi = <wi,x>+bi  为 0 或者 1
y = [y1, y2, y3, y4,...] one-hot encoding
w = [w1, w2, w3, w4,...]

改进：
softmax(oi)= exp(oi)/sum(exp(oi)) 将输入向量 oi 转换为概率分布
yi = softmax(oi)
Objective: minimize(loss) Cross-entropy 交叉熵
Cross-entropy = sum(yi*log(softmax(oi)))

- 求解线性模型 SGD Stochastic Gradient descent 随机梯度下降
  Min-batch SGD 小批量梯度下降
  w 模型向量(包括偏差 b, 输入特征加一列全 1 的特征) 
  b 批量大小
  n 学习率
  t 迭代次数
  w-w-n▲(x, y, w) # 梯度变化最大的导数

#### 神经网络

特征提取有神经网络操作

常见

- 多层感知机 MLP Multilayer Perceptron

  全连接层 dense with 1 output

  softmax? 多个输出

  全连接层：全连接层是最基本的神经网络层，它将输入向量映射到输出向量。

  参数大小和输入输出有关

  为什么需要激活函数：

  \1. 激活函数能够将输入映射到更复杂的空间，从而解决非线性问题。

  \2. 激活函数能够帮助模型学习更复杂的模式和特征。

  \3. 激活函数能够帮助模型学习非线性关系，从而解决非线性问题

  激活函数：

  sigmoid=1/(1+exp(-x))

  Relu=max(0,x)

- 卷积神经网络

  **CNN Convolutional Neural Network** 

  选取k*k的卷积核kernel，只需要对卷积核进行计算获得参数，参数可重用到其他卷积核中

  常用于识别图像中的物体

  通道？

  池化？是啥？

  池化层：缩小卷积核，减少参数量，减少计算量，减少过拟合

  卷积层——>激活层-->池化层——>全连接层

- 循环神经网络

  **Recurrent Neural Network**

  RNN 是时间序列数据的处理方法

  <img src="D:\File\typora_file\image-20241007113728843.png" alt="image-20241007113728843" style="zoom:80%;" />

  <span style="font-size:1.3em"> **双向神经网络和多层RNN**</span>

  <img src="D:\File\typora_file\image-20241007114752399.png" alt="image-20241007114752399" style="zoom:80%;" />

- Transformer

## Model Validation

### 评估指标

TP: 正确预测的个数
TN: 负类预测正确的个数
FP: 负类预测错误的个数
FN: 正类预测错误的个数

- Accuracy: 正确率 
- Precision: 精准率 对某个具体的类，==TP/(TP+FP) 预测为1&原始为1的个数/预测为1的总个数
- Recall: 召回率 对某个具体的类，==TP/(TP+FN) 预测为1&原始为1的个数/原始为1的总个数
- F1: F1-score = 2*Precision*Recall/(Precision+Recall) 平衡精准率和召回率
- AUC: Area Under Curve AOC=ROC曲线下面积
ROC 曲线：
- 纵坐标TPR: True Positive Rate 召回率
- 横坐标FPR: False Positive Rate 1-Specificity

### 过拟合和欠拟合

过拟合 overfit：训练集准确率很高，但是测试集准确率较低

欠拟合 underfit：训练集准确率较低，但是测试集准确率较高

模型的复杂度：High complexity models can memorize the training data

### 模型验证

泛化误差：模型在训练集和测试集上的误差之和

Tese set: 测试集，用来评估模型的泛化能力 can be used once 

Validation set: 验证集,part of training dataset,can be used multiple times

k-fold cross validation: k折交叉验证 训练集被分成k份，每次用k-1份训练，用剩余的1份作为验证集

## 模型偏差

- 偏差
- 方差





# 深度学习



## NLP 自然语言处理

图灵鸭子模仿游戏

Advances in Natural Language Processing

One-Hot Representation ：一维向量表示 假设所有的词都是独立的，不会考虑相似度

Represent Word by Context：词和上下文有关 （词表过大、对频率较低的词表示也不好）

<img src="D:\File\typora_file\image-20240921102651382.png" alt="image-20240921102651382" style="zoom:80%;" />

**Language Model**

<img src="D:\File\typora_file\image-20240921103001993.png" alt="image-20240921103001993" style="zoom:80%;" />

一个序列成为合法语句的概率、以及根据前边的话预测下一个词语

**N-gram Model**: 当前词预测只考虑前边 N 词

## 神经网络 Artificial Neural Nerwork

线性变换 前向传播

<img src="D:\File\typora_file\image-20240921105928829.png" alt="image-20240921105928829" style="zoom:80%;" />

<img src="D:\File\typora_file\image-20240921110327920.png" alt="image-20240921110327920" style="zoom:80%;" />

**激活函数：** 防止非线性神经网络塌陷成单一的神经网络 

softmax...

<img src="D:\File\typora_file\image-20240921110546170.png" alt="image-20240921110546170" style="zoom:80%;" />

**损失函数本质上就是计算预测值和真实值的差距的一类型函数**

<img src="D:\File\typora_file\image-20240921111604494.png" alt="image-20240921111604494" style="zoom:80%;" />

**梯度下降法减少损失函数的值** α-学习率

<img src="D:\File\typora_file\image-20240921112016326.png" alt="image-20240921112016326" style="zoom:80%;" />

<img src="D:\File\typora_file\image-20240921112159165.png" alt="image-20240921112159165" style="zoom:80%;" />

 **反向传播算法**：

<img src="D:\File\typora_file\image-20240921112848328.png" alt="image-20240921112848328" style="zoom:80%;" />

前向传播和反向传播

```
前向传播（Forward Propagation）和反向传播（Backpropagation）是训练人工神经网络时使用的两种核心算法。它们通常一起使用来调整网络中的权重，以最小化预测输出与实际输出之间的差异。下面简要介绍一下这两种方法：

### 前向传播

前向传播是指输入数据从输入层开始，经过隐藏层，直到输出层的整个过程。在这个过程中，每一层的神经元都会根据上一层传递过来的数据进行计算，并将结果传递给下一层。这个过程可以看作是数据通过网络的流动，每经过一个节点，都会应用激活函数来决定该节点是否“激活”。

在前向传播过程中，输入数据会依次通过各个层，每一层都会计算其净输入（加权输入加上偏置项），然后应用非线性激活函数来产生输出。这些输出作为输入传递到下一层，直到达到输出层，得到最终的预测值。

### 反向传播

反向传播是一种用于训练人工神经网络的监督学习方法，它基于梯度下降法来最小化损失函数。当有了前向传播得到的预测输出后，反向传播会计算预测输出与实际输出之间的误差，并试图通过调整网络权重来减小这个误差。

在反向传播中，从输出层开始，向后计算每个权重对总误差的贡献（即误差相对于权重的偏导数）。这通常涉及到链式法则的应用，因为它需要计算误差相对于每个权重的梯度。一旦得到了这些梯度，就可以更新权重，使得下次遇到同样的输入时，网络能够给出更接近真实标签的输出。

反向传播的核心在于利用了损失函数关于权重的梯度来进行权重更新。这使得网络能够“学习”如何更好地映射输入到正确的输出。

前向传播和反向传播通常是交替进行的，在一次完整的训练周期（epoch）中，会先进行前向传播得到预测结果，再进行反向传播调整权重，然后再用调整后的权重进行新的前向传播，如此循环迭代，直到网络收敛或者达到预定的训练次数。
```

### Word2Vec

基于滑动窗口

<img src="D:\File\typora_file\image-20240921113519760.png" alt="image-20240921113519760" style="zoom:80%;" />

- **Continuous bag-of-words (CBOW)**

  根据 context(上下文)预测 target 

  <img src="D:\File\typora_file\image-20240921114109071.png" alt="image-20240921114109071" style="zoom:80%;" />

- **Continuous Skip-gram**

  根据 target 预测 context

  <img src="D:\File\typora_file\image-20240921113958049.png" alt="image-20240921113958049" style="zoom:80%;" />

## 数据操作 ＋ 数据预处理

N 维数组是机器学习和神经网络的主要数据结构



